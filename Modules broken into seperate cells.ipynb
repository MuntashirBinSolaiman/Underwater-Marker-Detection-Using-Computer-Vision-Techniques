{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author - Muntashir Bin Solaiman\n",
    "Last modified - 22-03-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelLoader Class - Responsible for loading and setting up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "class ModelLoader:\n",
    "    def __init__(self, model_type, checkpoint_path, device='cuda:0'):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model_type = model_type\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.sam_model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Loads the model using the specified checkpoint.\"\"\"\n",
    "        self.sam_model = sam_model_registry[self.model_type](checkpoint=self.checkpoint_path)\n",
    "        self.sam_model.to(device=self.device)\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"Returns the loaded model.\"\"\"\n",
    "        return self.sam_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaskGenerator Class - Handles the generation of segmentation masks from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "\n",
    "class MaskGenerator:\n",
    "    def __init__(self, model):\n",
    "        self.mask_generator = SamAutomaticMaskGenerator(model)\n",
    "\n",
    "    def generate_masks(self, image):\n",
    "        \"\"\"Generates segmentation masks for the given image.\"\"\"\n",
    "        return self.mask_generator.generate(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageProcessor Class - Manages the processing of individual images, including loading, converting formats, and passing them through the mask generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, mask_generator):\n",
    "        self.mask_generator = mask_generator\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"Loads and processes the image.\"\"\"\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        masks = self.mask_generator.generate_masks(image_rgb)\n",
    "        return image_bgr, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoundingBoxDrawer Class - Draws bounding boxes around detected regions in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# class BoundingBoxDrawer:\n",
    "#     @staticmethod\n",
    "#     def draw_bounding_boxes(image_bgr, anns):\n",
    "#         \"\"\"Draws bounding boxes around the detected regions.\"\"\"\n",
    "#         fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "#         ax.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))  # Show original image\n",
    "\n",
    "#         # Draw bounding boxes\n",
    "#         for ann in anns.xyxy:\n",
    "#             x1, y1, x2, y2 = ann\n",
    "#             ax.add_patch(patches.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2))\n",
    "\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBoxDrawer:\n",
    "    @staticmethod\n",
    "    def draw_bounding_boxes(anns, image_bgr):\n",
    "        if len(anns) == 0:  # Check if anns is a list and has items\n",
    "            return\n",
    "\n",
    "        # If anns is a list of bounding boxes, directly handle it\n",
    "        areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in anns]  # Calculate area for each box\n",
    "        sorted_anns = sorted(zip(anns, areas), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "        ax.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for ann, area in sorted_anns:\n",
    "            x1, y1, x2, y2 = ann\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2))\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AnnotationDisplay Class - Handles the display of annotations and visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AnnotationDisplay:\n",
    "#     @staticmethod\n",
    "#     def show_annotations(detections, image_bgr):\n",
    "#         \"\"\"Displays the annotations on the image.\"\"\"\n",
    "#         if len(detections.xyxy) == 0:\n",
    "#             return\n",
    "        \n",
    "#         areas = (detections.xyxy[:, 2] - detections.xyxy[:, 0]) * (detections.xyxy[:, 3] - detections.xyxy[:, 1])\n",
    "#         sorted_anns = sorted(zip(detections.xyxy, areas), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#         BoundingBoxDrawer.draw_bounding_boxes(image_bgr, sorted_anns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationDisplay:\n",
    "    def __init__(self):\n",
    "        self.mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.CLASS)\n",
    "\n",
    "    def show_annotations(self, masks, image_bgr):\n",
    "        detections = sv.Detections.from_sam(masks)  # Error: detections is a list\n",
    "        BoundingBoxDrawer.draw_bounding_boxes(detections, image_bgr)  # Error: detections needs to be handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SegmentationPipeline Class - A high-level class that integrates the model loading, mask generation, image processing, and annotation display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "class SegmentationPipeline:\n",
    "    def __init__(self, model_loader, mask_generator, image_processor, annotation_display):\n",
    "        self.model_loader = model_loader\n",
    "        self.mask_generator = mask_generator\n",
    "        self.image_processor = image_processor\n",
    "        self.annotation_display = annotation_display\n",
    "\n",
    "    def run(self, image_paths):\n",
    "        \"\"\"Runs the entire segmentation pipeline.\"\"\"\n",
    "        for image_path in image_paths:\n",
    "            image_bgr, masks = self.image_processor.process_image(image_path)\n",
    "            detections = sv.Detections.from_sam(masks)  # Assuming sv.Detections.from_sam() is correctly implemented\n",
    "            self.annotation_display.show_annotations(detections, image_bgr)\n",
    "        print(\"Segmentation complete for all images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationPipeline:\n",
    "    def __init__(self, model_type, checkpoint_path, device, image_paths):\n",
    "        self.model_loader = ModelLoader(model_type, checkpoint_path, device)\n",
    "        self.mask_generator = MaskGenerator(self.model_loader.model)\n",
    "        self.annotation_display = AnnotationDisplay()\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        for image_path in self.image_paths:\n",
    "            image_processor = ImageProcessor(image_path)\n",
    "            masks = self.mask_generator.generate_masks(image_processor.image_rgb)\n",
    "            self.annotation_display.show_annotations(masks, image_processor.image_bgr)\n",
    "        print(\"Segmentation complete for all images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DetectionResults Class - Stores and manages the results of detections, including segmentation masks and bounding boxes for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionResults:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "\n",
    "    def add_results(self, image_path, masks):\n",
    "        \"\"\"Stores segmentation results for an image.\"\"\"\n",
    "        self.results[image_path] = masks\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Returns all stored results.\"\"\"\n",
    "        return self.results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize classes\n",
    "    model_loader = ModelLoader(model_type=\"vit_h\", checkpoint_path=\"/home/ad/22021468/sam_checkpoints/sam_vit_h_4b8939.pth\")\n",
    "    mask_generator = MaskGenerator(model_loader.get_model())\n",
    "    image_processor = ImageProcessor(mask_generator)\n",
    "    annotation_display = AnnotationDisplay()\n",
    "    segmentation_pipeline = SegmentationPipeline(model_loader, mask_generator, image_processor, annotation_display)\n",
    "\n",
    "    # List of image paths to process\n",
    "    image_paths = [\n",
    "        \"/data/shared/CSIT_Placement_2025_3D_Reef/CBHE_BA2D_P1/images/frame_00001.JPG\",\n",
    "        \"/data/shared/CSIT_Placement_2025_3D_Reef/CBHE_BA2D_P1/images/frame_00002.JPG\",\n",
    "    ]\n",
    "\n",
    "    # Run the segmentation pipeline\n",
    "    segmentation_pipeline.run(image_paths)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndustryExperience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
